{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CuPy is not correctly installed. Please check your environment, uninstall Chainer and reinstall it with `pip install cupy --no-cache-dir -vvvv`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-91fe74f79b08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/cupy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m            \u001b[1;34m'uninstall Chainer and reinstall it with `pip install cupy '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m            '--no-cache-dir -vvvv`.')\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRuntimeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/cupy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# core is a c-extension module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/cupy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minternal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mndarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CuPy is not correctly installed. Please check your environment, uninstall Chainer and reinstall it with `pip install cupy --no-cache-dir -vvvv`."
     ]
    }
   ],
   "source": [
    "#generic\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "import tensorflow as tf\n",
    "# import quandl \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yahoo_finance import Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_by_key(key, data):\n",
    "    data_it = iter(data)\n",
    "    return_data = []\n",
    "    flag = True\n",
    "    for d in data_it:\n",
    "        if key !=\"Date\":\n",
    "            return_data.append(float(d[key]))\n",
    "        else:\n",
    "            return_data.append(d[key])\n",
    "        \n",
    "    return np.array(return_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_by_list_fixed(name_list, start_date, end_date, data_type=\"Open\"):\n",
    "    share_list = []\n",
    "    new_name_list = []\n",
    "    for name in name_list:\n",
    "        try:\n",
    "            share_list.append(Share(name))\n",
    "            new_name_list.append(name)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    stock_data_list = []\n",
    "    date = []\n",
    "    flag = True\n",
    "    N_data = 0\n",
    "    fail_name_list = []\n",
    "    ret_name_list = []\n",
    "    for idx, share in enumerate(share_list):\n",
    "        name = new_name_list[idx]\n",
    "        try:\n",
    "            hist_data = share.get_historical(start_date=start_date, end_date=end_date)\n",
    "            stock_data = map(float, get_data_by_key(key=data_type, data=hist_data))\n",
    "            n_data = len(stock_data)\n",
    "            if n_data == 0:\n",
    "                fail_name_list.append(name)\n",
    "            date.append(get_data_by_key(key='Date', data=hist_data))\n",
    "            stock_data_list.append(stock_data)\n",
    "            ret_name_list.append(name)\n",
    "        except:\n",
    "            pass\n",
    "    print (\"fail_name_list: \", fail_name_list)\n",
    "    return np.array(stock_data_list).T, date, ret_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "energy = [\"PTR\", \"XOM\", \"CVX\", \"RDS-A\", \"BP\", \"TOT\", \"SLB\", \"KMI\", \"COP\", \"CEO\", \n",
    "          \"E\", \"STO\", \"OXY\", \"PBR\", \"EOG\", \"APC\", \"SU\", \"ENB\", \"HAL\", \"WMB\"]\n",
    "financial = [\"WFC\", \"JPM\", \"HSBC\", \"BAC\", \"C\", \"SAN\", \"MTU\", \"RY\", \"WBK\", \"TD\", \"GS\", \n",
    "             \"LYG\", \"AXP\", \"AIG\", \"MS\", \"ITUB\", \"BCS\", \"BBVA\"]\n",
    "healthcare = [\"NVS\", \"JNJ\", \"PFE\", \"MRK\", \"GILD\", \"SNY\", \"AMGN\", \"NVO\", \"GSK\", \"UNH\",\n",
    "             \"MDT\", \"BMY\", \"CELG\", \"BIIB\", \"AZN\", \"LLY\", \"ABT\", \"AGN\", \"VRX\", \"TEVA\",\n",
    "             \"TMO\", \"SHPG\", \"REGN\"]\n",
    "buisiness = [\"ACN\", \"LMT\", \"CNI\", \"FDX\", \"DAL\", \"CSX\", \"AAL\", \"CP\", \"NSC\", \"NOC\", \"LUV\"]\n",
    "telecom = [\"CHL\", \"VZ\", \"T\", \"VOD\", \"NTT\", \"AMX\", \"CHA\", \"BT\", \"CHU\", \"ORAN\", \"BCE\",\n",
    "           \"CHT\", \"SKM\", \"TI\", \"TU\", \"S\", \"TLK\", \"DUK\", \"NGG\", \"D\", \"SO\", \"EXC\", \"KEP\",\n",
    "          \"AEP\", \"SRE\", \"PCG\", \"HNP\", \"PPL\", \"PEG\", \"EIX\", \"ETP\", \"ED\", \"ENI\", \"XEL\", \"ES\", \"FE\"]\n",
    "hardware = [\"AAPL\", \"ORCL\", \"IBM\", \"INTC\", \"CSCO\", \"TSM\", \"QCOM\", \"HPQ\", \"TXN\", \"EMC\",\n",
    "           \"CAJ\", \"ASML\", \"ERIC\", \"SNE\", \"AVGO\", \"MU\", \"GLW\", \"NXPI\", \"NOK\",\n",
    "           \"AMAT\", \"WDC\", \"WIT\", \"ADI\", \"STX\", \"APH\"]\n",
    "software = [\"MSFT\", \"GOOGL\", \"BIDU\", \"EBAY\", \"SAP\", \"CRM\", \"YHOO\", \"VMW\",\n",
    "            \"ADBE\", \"CTSH\", \"INFY\", \"INTU\", \"LNKD\", \"RHT\", \"NTES\", \"CHKP\", \n",
    "            \"CA\", \"ADSK\", \"AKAM\", \"NVDA\"]\n",
    "industrial = [\"GE\", \"V\", \"MA\", \"UTX\", \"MMM\", \"BA\", \"UNP\", \"UPS\", \"HON\", \"DHR\", \"CAT\", \n",
    "              \"ABB\", \"GD\", \"ADP\", \"EMR\", \"ITW\", \"ECL\", \"TEL\", \"PCAR\", \"WM\"]\n",
    "manufacturing = [\"TM\", \"HMC\", \"F\", \"GM\", \"JCI\", \"TSLA\", \"TTM\", \"CMI\", \"DLPH\", \"MGA\",\n",
    "                \"CMI\", \"DLPH\", \"MGA\", \"GPC\", \"BWA\", \"HOG\", \"ALV\", \"HAR\", \"LEA\", \"LKQ\", \n",
    "                 \"WBC\", \"GT\", \"FCAU\", \"NSANY\", \"NAV\"]\n",
    "consumer = [\"PG\", \"BUD\", \"KO\", \"PEP\", \"UL\", \"PM\", \"BTI\", \"MO\", \"ABEV\", \"DEO\", \"MDLZ\",\n",
    "            \"CL\", \"MON\", \"MCK\", \"KMB\", \"WHR\", \"DIS\", \"CMCSA\", \"FOXA\", \"TWX\", \"TWC\",\n",
    "           \"DISH\", \"CBS\", \"DISCA\", \"TV\", \"CHTR\", \"QVCA\", \"OMC\", \"NLSN\", \n",
    "           \"PSO\", \"SJR\", \"NFLX\"]\n",
    "diversified = [\"BRK-A\", \"BRK-B\", \"UTX\", \"BC\", \"RTN\", \"OLN\", \"ITT\", \"MSBHY\", \"KWHIY\", \n",
    "               \"ABB\", \"IEP\", \"GE\"]\n",
    "retailing = [\"WMT\", \"AMZN\", \"HD\", \"MCD\", \"NKE\", \"SBUX\", \"CVS\", \"WBA\", \"PCLN\", \"COST\", \n",
    "            \"TGT\", \"TJX\", \"LVS\", \"YUM\", \"CCL\", \"LUX\", \"DG\", \"M\", \"AZO\", \"ROST\", \"CMG\", \"GPS\", \n",
    "            \"DLTR\", \"RCL\", \"KSS\", \"HOT\", \"JWN\"]\n",
    "\n",
    "input_list = energy + financial + healthcare + buisiness + telecom\\\n",
    "+ hardware + software + industrial + manufacturing + consumer + diversified + retailing\n",
    "print (len(input_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!!\n",
      "fail_name_list:  []\n",
      "time for getting training_data: 981.886349201\n"
     ]
    }
   ],
   "source": [
    "print (\"Started!!\")\n",
    "\n",
    "st = time.time()\n",
    "start_date=\"2014-04-01\"\n",
    "end_date=\"2016-04-01\"\n",
    "input_data, date, input_list = get_data_by_list_fixed(input_list, start_date=start_date, end_date=end_date) \n",
    "elapsed = time.time() - st\n",
    "print (\"time for getting training_data:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 248)\n"
     ]
    }
   ],
   "source": [
    "print (input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PTR'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert date label for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def convert_time_format(date):\n",
    "    date_tilde = date.split(\"-\")\n",
    "    date_tilde = map(int, date_tilde)\n",
    "    return datetime.datetime(*date_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_each = date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_label=[]\n",
    "for i in xrange(len(date_each)):\n",
    "    date_label.append(convert_time_format(date_each[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b2e654b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(date_label, input_data[:, 0])\n",
    "plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take all of actions into consideration, action space has huge dimention. So, I will just think about short, call, and hold for 'PTR' as all actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQNMLP(object):\n",
    "    def __init__(self, layers, activation=tf.sigmoid,  gam=0.95, is_initialize=True):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        Args:\n",
    "            layers(list): list of the number of nodes in each layer\n",
    "            gam (float): decay rate\n",
    "            is_intialized(optional) (bool): if True, the graph will be initialized\n",
    "        \"\"\"\n",
    "        print (\"building model....\")\n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        \n",
    "        # intialize graph to avoid conflications\n",
    "        if is_initialize is True:\n",
    "            sess  = tf.InteractiveSession()\n",
    "            tf.reset_default_graph()\n",
    "            sess.close()\n",
    "            \n",
    "        self._action = tf.placeholder(tf.int32, name= \"action\")\n",
    "        self._cash = tf.placeholder(tf.float32, name=\"cash\")\n",
    "        self._stock = tf.placeholder(tf.int32, name=\"stock\")\n",
    "        self._price = tf.placeholder(tf.float32, [layers[0] - 3], name=\"price\")\n",
    "        \n",
    "        # change format for training\n",
    "        action_tilde = tf.to_float(self._action, name=\"action_tilde\")\n",
    "        stock_tilde = tf.to_float(self._stock, name=\"stock_tilde\")\n",
    "        price_tilde = tf.unpack(self._price)\n",
    "        input_list = [action_tilde] + [stock_tilde] + [self._cash] + price_tilde\n",
    "        input_tensor= tf.pack(input_list)\n",
    "        \n",
    "        self._input = tf.reshape(input_tensor, shape=[1, layers[0]], name=\"input\")\n",
    "        self._target = tf.placeholder(tf.float32, [1, 1], name=\"target\")\n",
    "        \n",
    "        # normalization for input\n",
    "        shape = [self.layers[0]]\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=shape), name=\"gamma\")\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=shape), name=\"beta\")\n",
    "        self.normalized_input = self.batch_normalization(self._input, shape, gamma, beta)\n",
    "                \n",
    "        # keep parameters for pretraining\n",
    "        self.gamma_list = []\n",
    "        self.beta_list = []\n",
    "        self.gamma_list.append(gamma)\n",
    "        self.beta_list.append(beta)\n",
    "        \n",
    "        # parameters\n",
    "        self.W_list = []\n",
    "        self.b_list = []\n",
    "        \n",
    "        # the name of variable scope will be layer0, layer1, ...\n",
    "        x = self.normalized_input\n",
    "        for i_layer in xrange(len(self.layers) - 1):\n",
    "            with tf.variable_scope(\"layer%d\" % i_layer):\n",
    "                n_in = self.layers[i_layer]\n",
    "                n_out = self.layers[i_layer + 1]\n",
    "                W = self.weight_variable([n_in, n_out])\n",
    "                b = self.bias_variable([n_out])\n",
    "                \n",
    "                # keep parameters for pretraining\n",
    "                self.W_list.append(W)\n",
    "                self.b_list.append(b)\n",
    "                \n",
    "                z = tf.matmul(x, W) + b\n",
    "                \n",
    "            # we will not apply activation function for the last layer\n",
    "            if i_layer == len(self.layers) - 2:\n",
    "                self._Q = z\n",
    "            else:\n",
    "                shape = [self.layers[i_layer + 1]]\n",
    "                gamma = tf.Variable(tf.constant(1.0, shape=shape), name=\"gamma\")\n",
    "                beta = tf.Variable(tf.constant(0.0, shape=shape), name=\"beta\")\n",
    "                \n",
    "                # keep parameters for pretraining\n",
    "                self.gamma_list.append(gamma)\n",
    "                self.beta_list.append(beta)\n",
    "                \n",
    "                normalized_z = self.batch_normalization(z, shape, gamma, beta)\n",
    "                x = self.activation(normalized_z)\n",
    "        \n",
    "        # training graph\n",
    "        self._learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        self.loss = tf.reduce_mean(tf.square(self._Q - self._target))\n",
    "        # fixate on using this optimizer, otherwize, otherwise endup using unecessary graph nose\n",
    "        self.optimizer = tf.train.AdamOptimizer(self._learning_rate, name=\"Optimizer\")\n",
    "        self.train = self.optimizer.minimize(self.loss)   \n",
    "        \n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=1.0)\n",
    "        return tf.Variable(initial, name=\"weight\")\n",
    "        \n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "        return tf.Variable(initial, name=\"bias\")\n",
    "        \n",
    "    def batch_normalization(self, input, shape, gamma=None, beta=None):\n",
    "        # input should be hidden_dim\n",
    "        eps = 1e-5\n",
    "        if gamma is None:\n",
    "            gamma = tf.Variable(tf.constant(1.0, shape=shape))\n",
    "        if beta is None:\n",
    "            beta = tf.Variable(tf.constant(0.0, shape=shape))\n",
    "        mean, variance = tf.nn.moments(input, [0])\n",
    "        return gamma * (input - mean) / tf.sqrt(variance + eps) + beta\n",
    "    \n",
    "    def eps_greedy(self, eps, cash, stock, price, sess):\n",
    "        \"\"\"Return action chosen by greedy algorithm\"\"\"\n",
    "        u = np.random.uniform()\n",
    "        actions = [-1, 0, 1]\n",
    "        if u < 1 - eps:\n",
    "            q_list = []\n",
    "            for a in actions:\n",
    "                q = self._Q.eval(session=sess, \n",
    "                                 feed_dict={self._action: a, \n",
    "                                            self._cash: cash,\n",
    "                                            self._stock: stock,\n",
    "                                            self._price: price})\n",
    "                q_list.append(q)\n",
    "            action = actions[np.argmax(q_list)]\n",
    "        else:\n",
    "            action = actions[np.random.randint(0, 3)]\n",
    "        \n",
    "        return action\n",
    "                \n",
    "    \n",
    "    def training(self, whole_stock, trade_stock, n_memory=20, eps=0.1, init_cash=10000, init_stock=0, gam=0.95, learning_rate=1e-4, n_epochs=100):\n",
    "        \"\"\"training DQN which consider three actions; sell, buy, hold\n",
    "              money and n_stock are considered as state variable\n",
    "        \n",
    "        Args:\n",
    "            data (list): stock price for one company\n",
    "            n_memory (int): the number of data that is used for Experience Replay\n",
    "            eps (float): the epsilon of greedy epsilon used for behavior policy\n",
    "            init_cash (float): initial available cash\n",
    "            init_stock (int): the number of stock data \n",
    "        \"\"\"\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        saver = tf.train.Saver()\n",
    "        T = len(whole_stock)\n",
    "        print_freq = int(n_epochs / 10)\n",
    "        \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_op)\n",
    "            value_list  = []\n",
    "            for epoch in xrange(n_epochs):\n",
    "                lr = learning_rate\n",
    "                cash = init_cash\n",
    "                stock = init_stock\n",
    "                price = whole_stock[0]\n",
    "                # memory pool used for Experience Replay\n",
    "                # length should be less than n_memory\n",
    "                memory = []\n",
    "                for t in xrange(T - 1):\n",
    "                    # select action with e-greedy\n",
    "                    # but:+1, hold: 0, sell -1\n",
    "                    action = self.eps_greedy(eps, cash, stock, price, sess)\n",
    "                    new_cash = cash - trade_stock[t] * action\n",
    "                    new_stock = stock + action\n",
    "                    new_price = whole_stock[t + 1]\n",
    "                    # add memory pools whose capacity is up to n_memory\n",
    "                    reward = new_stock * (trade_stock[t + 1] - trade_stock[t])\n",
    "                    transition = [cash, stock, price, action, reward, new_cash, new_stock, new_price]\n",
    "                    if len(memory) == n_memory:\n",
    "                        del memory[0]\n",
    "                    memory.append(transition)\n",
    "                    cash = new_cash\n",
    "                    stock = new_stock\n",
    "                    price = new_price\n",
    "                    \n",
    "                    # select transition from pool\n",
    "                    idx = np.random.randint(0, len(memory))\n",
    "                    trans = memory[idx]\n",
    "                    c = trans[0]\n",
    "                    s = trans[1]\n",
    "                    p = trans[2]\n",
    "                    a = trans[3]\n",
    "                    r = trans[4]\n",
    "                    new_c = trans[5]\n",
    "                    new_s = trans[6]\n",
    "                    new_p = trans[7]\n",
    "                    new_a = self.eps_greedy(eps, new_c, new_s, new_p, sess)\n",
    "                    q = self._Q.eval(session=sess, \n",
    "                                     feed_dict={self._action: new_a, \n",
    "                                                self._cash: new_c,\n",
    "                                                self._stock: new_s,\n",
    "                                                self._price: new_p})\n",
    "                    target = q + r\n",
    "                    sess.run(self.train, \n",
    "                             feed_dict={self._action: a, \n",
    "                                        self._cash: c,\n",
    "                                        self._stock: s,\n",
    "                                        self._price: p,\n",
    "                                        self._target: target,\n",
    "                                        self._learning_rate:lr})  \n",
    "                    \n",
    "                value = cash + trade_stock[-1] * stock\n",
    "                value_list.append(value)\n",
    "                if epoch % print_freq == 0:\n",
    "                    print (\"epoch: %d, final value:%f, stock:%d, cash:%f\" % (epoch, value, stock, cash))\n",
    "                    print (\"elapsed time:\", time.time() - st)\n",
    "           \n",
    "            # save_path = saver.save(sess, \"/jupyter/tomoaki/DQN/trained_params.ckpt\")\n",
    "            save_path = saver.save(sess, \"/home/tomoaki/alpaca/notebooks//DQN/trained_params.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "           \n",
    "        return value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n",
      "start!\n",
      "training....\n",
      "epoch: 0, final value:7350.261355, stock:-457, cash:57679.669984\n",
      "elapsed time: 8.93725204468\n",
      "epoch: 10, final value:7250.321320, stock:-452, cash:57029.079964\n",
      "elapsed time: 96.6960039139\n",
      "epoch: 20, final value:7097.621313, stock:-461, cash:57867.549930\n",
      "elapsed time: 184.169920921\n",
      "epoch: 30, final value:6624.991313, stock:-453, cash:56513.879954\n",
      "elapsed time: 273.026759863\n",
      "epoch: 40, final value:6963.131376, stock:-460, cash:57622.929996\n",
      "elapsed time: 361.735897064\n",
      "epoch: 50, final value:7325.141312, stock:-447, cash:56553.249971\n",
      "elapsed time: 450.004987001\n",
      "epoch: 60, final value:7048.211354, stock:-458, cash:57487.749980\n",
      "elapsed time: 539.434099913\n",
      "epoch: 70, final value:7511.851236, stock:-440, cash:55969.049916\n",
      "elapsed time: 627.813276052\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-2e4d51a726bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"start!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_stock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrade_stock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrade_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_cash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"computation time:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-c7b16dd8118f>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, whole_stock, trade_stock, n_memory, eps, init_cash, init_stock, gam, learning_rate, n_epochs)\u001b[0m\n\u001b[0;32m    194\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_price\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                                         self._learning_rate:lr})  \n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrade_stock\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 655\u001b[1;33m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 723\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_idx = date_label.index(datetime.datetime(2015, 4, 1, 0, 0))\n",
    "trade_data = input_data[:, 0]\n",
    "n_in = len(input_data[0]) + 3\n",
    "n_hid1 = int(n_in * 0.3)\n",
    "n_hid2 = int(n_hid1 * 0.3)\n",
    "n_out = 1\n",
    "layers = [n_in, n_hid1, n_hid2, n_out]\n",
    "train = input_data[:test_idx]\n",
    "test = input_data[test_idx:]\n",
    "date_test = date_label[test_idx:]\n",
    "\n",
    "dqn = DQNMLP(layers=layers)\n",
    "print (\"start!\")\n",
    "st = time.time()\n",
    "value = dqn.training(whole_stock=input_data, trade_stock=trade_data, n_epochs=100, init_cash=10000)\n",
    "elapsed = time.time() - st\n",
    "print (\"computation time:\", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison, we do the same thing using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQNMLP_cpu(object):\n",
    "    def __init__(self, layers, activation=tf.sigmoid,  gam=0.95, is_initialize=True):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        Args:\n",
    "            layers(list): list of the number of nodes in each layer\n",
    "            gam (float): decay rate\n",
    "            is_intialized(optional) (bool): if True, the graph will be initialized\n",
    "        \"\"\"\n",
    "        print (\"building model....\")\n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        \n",
    "        # intialize graph to avoid conflications\n",
    "        if is_initialize is True:\n",
    "            sess  = tf.InteractiveSession()\n",
    "            tf.reset_default_graph()\n",
    "            sess.close()\n",
    "        with tf.device('/cpu:0'):   \n",
    "            self._action = tf.placeholder(tf.int32, name= \"action\")\n",
    "            self._cash = tf.placeholder(tf.float32, name=\"cash\")\n",
    "            self._stock = tf.placeholder(tf.int32, name=\"stock\")\n",
    "            self._price = tf.placeholder(tf.float32, [layers[0] - 3], name=\"price\")\n",
    "        \n",
    "            # change format for training\n",
    "            action_tilde = tf.to_float(self._action, name=\"action_tilde\")\n",
    "            stock_tilde = tf.to_float(self._stock, name=\"stock_tilde\")\n",
    "            price_tilde = tf.unpack(self._price)\n",
    "            input_list = [action_tilde] + [stock_tilde] + [self._cash] + price_tilde\n",
    "            input_tensor= tf.pack(input_list)\n",
    "        \n",
    "            self._input = tf.reshape(input_tensor, shape=[1, layers[0]], name=\"input\")\n",
    "            self._target = tf.placeholder(tf.float32, [1, 1], name=\"target\")\n",
    "        \n",
    "            # normalization for input\n",
    "            shape = [self.layers[0]]\n",
    "            gamma = tf.Variable(tf.constant(1.0, shape=shape), name=\"gamma\")\n",
    "            beta = tf.Variable(tf.constant(0.0, shape=shape), name=\"beta\")\n",
    "            self.normalized_input = self.batch_normalization(self._input, shape, gamma, beta)\n",
    "                \n",
    "            # keep parameters for pretraining\n",
    "            self.gamma_list = []\n",
    "            self.beta_list = []\n",
    "            self.gamma_list.append(gamma)\n",
    "            self.beta_list.append(beta)\n",
    "        \n",
    "            # parameters\n",
    "            self.W_list = []\n",
    "            self.b_list = []\n",
    "        \n",
    "            # the name of variable scope will be layer0, layer1, ...\n",
    "            x = self.normalized_input\n",
    "            for i_layer in xrange(len(self.layers) - 1):\n",
    "                with tf.variable_scope(\"layer%d\" % i_layer):\n",
    "                    n_in = self.layers[i_layer]\n",
    "                    n_out = self.layers[i_layer + 1]\n",
    "                    W = self.weight_variable([n_in, n_out])\n",
    "                    b = self.bias_variable([n_out])\n",
    "                \n",
    "                    # keep parameters for pretraining\n",
    "                    self.W_list.append(W)\n",
    "                    self.b_list.append(b)\n",
    "                \n",
    "                    z = tf.matmul(x, W) + b\n",
    "                \n",
    "                # we will not apply activation function for the last layer\n",
    "                if i_layer == len(self.layers) - 2:\n",
    "                    self._Q = z\n",
    "                else:\n",
    "                    shape = [self.layers[i_layer + 1]]\n",
    "                    gamma = tf.Variable(tf.constant(1.0, shape=shape), name=\"gamma\")\n",
    "                    beta = tf.Variable(tf.constant(0.0, shape=shape), name=\"beta\")\n",
    "                \n",
    "                    # keep parameters for pretraining\n",
    "                    self.gamma_list.append(gamma)\n",
    "                    self.beta_list.append(beta)\n",
    "                \n",
    "                    normalized_z = self.batch_normalization(z, shape, gamma, beta)\n",
    "                    x = self.activation(normalized_z)\n",
    "        \n",
    "            # training graph\n",
    "            self._learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "            self.loss = tf.reduce_mean(tf.square(self._Q - self._target))\n",
    "            # fixate on using this optimizer, otherwize, otherwise endup using unecessary graph nose\n",
    "            self.optimizer = tf.train.AdamOptimizer(self._learning_rate, name=\"Optimizer\")\n",
    "            self.train = self.optimizer.minimize(self.loss)   \n",
    "        \n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=1.0)\n",
    "        return tf.Variable(initial, name=\"weight\")\n",
    "        \n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "        return tf.Variable(initial, name=\"bias\")\n",
    "        \n",
    "    def batch_normalization(self, input, shape, gamma=None, beta=None):\n",
    "        # input should be hidden_dim\n",
    "        eps = 1e-5\n",
    "        if gamma is None:\n",
    "            gamma = tf.Variable(tf.constant(1.0, shape=shape))\n",
    "        if beta is None:\n",
    "            beta = tf.Variable(tf.constant(0.0, shape=shape))\n",
    "        mean, variance = tf.nn.moments(input, [0])\n",
    "        return gamma * (input - mean) / tf.sqrt(variance + eps) + beta\n",
    "    \n",
    "    def eps_greedy(self, eps, cash, stock, price, sess):\n",
    "        \"\"\"Return action chosen by greedy algorithm\"\"\"\n",
    "        u = np.random.uniform()\n",
    "        actions = [-1, 0, 1]\n",
    "        if u < 1 - eps:\n",
    "            q_list = []\n",
    "            for a in actions:\n",
    "                q = self._Q.eval(session=sess, \n",
    "                                 feed_dict={self._action: a, \n",
    "                                            self._cash: cash,\n",
    "                                            self._stock: stock,\n",
    "                                            self._price: price})\n",
    "                q_list.append(q)\n",
    "            action = actions[np.argmax(q_list)]\n",
    "        else:\n",
    "            action = actions[np.random.randint(0, 3)]\n",
    "        \n",
    "        return action\n",
    "                \n",
    "    \n",
    "    def training(self, whole_stock, trade_stock, n_memory=20, eps=0.1, init_cash=10000, init_stock=0, gam=0.95, learning_rate=1e-4, n_epochs=100):\n",
    "        \"\"\"training DQN which consider three actions; sell, buy, hold\n",
    "              money and n_stock are considered as state variable\n",
    "        \n",
    "        Args:\n",
    "            data (list): stock price for one company\n",
    "            n_memory (int): the number of data that is used for Experience Replay\n",
    "            eps (float): the epsilon of greedy epsilon used for behavior policy\n",
    "            init_cash (float): initial available cash\n",
    "            init_stock (int): the number of stock data \n",
    "        \"\"\"\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        saver = tf.train.Saver()\n",
    "        T = len(whole_stock)\n",
    "        print_freq = int(n_epochs / 10)\n",
    "        \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        with tf.device('/cpu:0'):\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init_op)\n",
    "                value_list  = []\n",
    "                for epoch in xrange(n_epochs):\n",
    "                    lr = learning_rate\n",
    "                    cash = init_cash\n",
    "                    stock = init_stock\n",
    "                    price = whole_stock[0]\n",
    "                    # memory pool used for Experience Replay\n",
    "                    # length should be less than n_memory\n",
    "                    memory = []\n",
    "                    for t in xrange(T - 1):\n",
    "                        # select action with e-greedy\n",
    "                        # but:+1, hold: 0, sell -1\n",
    "                        action = self.eps_greedy(eps, cash, stock, price, sess)\n",
    "                        new_cash = cash - trade_stock[t] * action\n",
    "                        new_stock = stock + action\n",
    "                        new_price = whole_stock[t + 1]\n",
    "                        # add memory pools whose capacity is up to n_memory\n",
    "                        reward = new_stock * (trade_stock[t + 1] - trade_stock[t])\n",
    "                        transition = [cash, stock, price, action, reward, new_cash, new_stock, new_price]\n",
    "                        if len(memory) == n_memory:\n",
    "                            del memory[0]\n",
    "                        memory.append(transition)\n",
    "                        cash = new_cash\n",
    "                        stock = new_stock\n",
    "                        price = new_price\n",
    "                    \n",
    "                        # select transition from pool\n",
    "                        idx = np.random.randint(0, len(memory))\n",
    "                        trans = memory[idx]\n",
    "                        c = trans[0]\n",
    "                        s = trans[1]\n",
    "                        p = trans[2]\n",
    "                        a = trans[3]\n",
    "                        r = trans[4]\n",
    "                        new_c = trans[5]\n",
    "                        new_s = trans[6]\n",
    "                        new_p = trans[7]\n",
    "                        new_a = self.eps_greedy(eps, new_c, new_s, new_p, sess)\n",
    "                        q = self._Q.eval(session=sess, \n",
    "                                         feed_dict={self._action: new_a, \n",
    "                                                self._cash: new_c,\n",
    "                                                self._stock: new_s,\n",
    "                                                self._price: new_p})\n",
    "                        target = q + r\n",
    "                        sess.run(self.train, \n",
    "                             feed_dict={self._action: a, \n",
    "                                        self._cash: c,\n",
    "                                        self._stock: s,\n",
    "                                        self._price: p,\n",
    "                                        self._target: target,\n",
    "                                        self._learning_rate:lr})  \n",
    "                    \n",
    "                    value = cash + trade_stock[-1] * stock\n",
    "                    value_list.append(value)\n",
    "                    if epoch % print_freq == 0:\n",
    "                        print (\"epoch: %d, final value:%f, stock:%d, cash:%f\" % (epoch, value, stock, cash))\n",
    "                        print (\"elapsed time:\", time.time() - st)\n",
    "           \n",
    "                # save_path = saver.save(sess, \"/jupyter/tomoaki/DQN/trained_params.ckpt\")\n",
    "                save_path = saver.save(sess, \"/home/tomoaki/alpaca/notebooks//DQN/trained_params.ckpt\")\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "           \n",
    "        return value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n",
      "start!\n",
      "training....\n",
      "epoch: 0, final value:6942.711348, stock:-466, cash:58263.289950\n",
      "elapsed time: 1.95241999626\n",
      "epoch: 10, final value:6709.331311, stock:-450, cash:56267.829961\n",
      "elapsed time: 19.1964230537\n",
      "epoch: 20, final value:7127.261329, stock:-449, cash:56575.629982\n",
      "elapsed time: 36.1533370018\n",
      "epoch: 30, final value:7080.571365, stock:-466, cash:58401.149967\n",
      "elapsed time: 52.9724709988\n",
      "epoch: 40, final value:6883.601288, stock:-449, cash:56331.969941\n",
      "elapsed time: 69.6491761208\n",
      "epoch: 50, final value:6733.851281, stock:-453, cash:56622.739922\n",
      "elapsed time: 87.5504851341\n",
      "epoch: 60, final value:6890.161378, stock:-469, cash:58541.129971\n",
      "elapsed time: 105.014996052\n",
      "epoch: 70, final value:7060.701334, stock:-457, cash:57390.109963\n",
      "elapsed time: 122.497781992\n",
      "epoch: 80, final value:6812.721339, stock:-461, cash:57582.649956\n",
      "elapsed time: 139.807360172\n",
      "epoch: 90, final value:6942.511306, stock:-453, cash:56831.399947\n",
      "elapsed time: 157.288625002\n",
      "Model saved in file: /home/tomoaki/alpaca/notebooks//DQN/trained_params.ckpt\n",
      "computation time: 173.450879097\n"
     ]
    }
   ],
   "source": [
    "dqn = DQNMLP_cpu(layers=layers)\n",
    "print (\"start!\")\n",
    "st = time.time()\n",
    "value = dqn.training(whole_stock=input_data, trade_stock=trade_data, n_epochs=100, init_cash=10000)\n",
    "elapsed = time.time() - st\n",
    "print (\"computation time:\", elapsed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmmm......, something strange. CPU is way faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this blog http://studylog.hateblo.jp/entry/2015/10/01/08362, we have to use \"cupy\" to make progmrams run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQNMLP(object):\n",
    "    def __init__(self, layers, activation=tf.sigmoid,  gam=0.95, is_initialize=True):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        Args:\n",
    "            layers(list): list of the number of nodes in each layer\n",
    "            gam (float): decay rate\n",
    "            is_intialized(optional) (bool): if True, the graph will be initialized\n",
    "        \"\"\"\n",
    "        print (\"building model....\")\n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        \n",
    "        # intialize graph to avoid conflications\n",
    "        if is_initialize is True:\n",
    "            sess  = tf.InteractiveSession()\n",
    "            tf.reset_default_graph()\n",
    "            sess.close()\n",
    "            \n",
    "        self._action = tf.placeholder(tf.int32, name= \"action\")\n",
    "        self._cash = tf.placeholder(tf.float32, name=\"cash\")\n",
    "        self._stock = tf.placeholder(tf.int32, name=\"stock\")\n",
    "        self._price = tf.placeholder(tf.float32, [layers[0] - 3], name=\"price\")\n",
    "        \n",
    "        # change format for training\n",
    "        action_tilde = tf.to_float(self._action, name=\"action_tilde\")\n",
    "        stock_tilde = tf.to_float(self._stock, name=\"stock_tilde\")\n",
    "        price_tilde = tf.unpack(self._price)\n",
    "        input_list = [action_tilde] + [stock_tilde] + [self._cash] + price_tilde\n",
    "        input_tensor= tf.pack(input_list)\n",
    "        \n",
    "        self._input = tf.reshape(input_tensor, shape=[1, layers[0]], name=\"input\")\n",
    "        self._target = tf.placeholder(tf.float32, [1, 1], name=\"target\")\n",
    "        \n",
    "        # normalization for input\n",
    "        shape = [self.layers[0]]\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=shape), name=\"gamma\")\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=shape), name=\"beta\")\n",
    "        self.normalized_input = self.batch_normalization(self._input, shape, gamma, beta)\n",
    "                \n",
    "        # keep parameters for pretraining\n",
    "        self.gamma_list = []\n",
    "        self.beta_list = []\n",
    "        self.gamma_list.append(gamma)\n",
    "        self.beta_list.append(beta)\n",
    "        \n",
    "        # parameters\n",
    "        self.W_list = []\n",
    "        self.b_list = []\n",
    "        \n",
    "        # the name of variable scope will be layer0, layer1, ...\n",
    "        x = self.normalized_input\n",
    "        for i_layer in xrange(len(self.layers) - 1):\n",
    "            with tf.variable_scope(\"layer%d\" % i_layer):\n",
    "                n_in = self.layers[i_layer]\n",
    "                n_out = self.layers[i_layer + 1]\n",
    "                W = self.weight_variable([n_in, n_out])\n",
    "                b = self.bias_variable([n_out])\n",
    "                \n",
    "                # keep parameters for pretraining\n",
    "                self.W_list.append(W)\n",
    "                self.b_list.append(b)\n",
    "                \n",
    "                z = tf.matmul(x, W) + b\n",
    "                \n",
    "            # we will not apply activation function for the last layer\n",
    "            if i_layer == len(self.layers) - 2:\n",
    "                self._Q = z\n",
    "            else:\n",
    "                shape = [self.layers[i_layer + 1]]\n",
    "                gamma = tf.Variable(tf.constant(1.0, shape=shape), name=\"gamma\")\n",
    "                beta = tf.Variable(tf.constant(0.0, shape=shape), name=\"beta\")\n",
    "                \n",
    "                # keep parameters for pretraining\n",
    "                self.gamma_list.append(gamma)\n",
    "                self.beta_list.append(beta)\n",
    "                \n",
    "                normalized_z = self.batch_normalization(z, shape, gamma, beta)\n",
    "                x = self.activation(normalized_z)\n",
    "        \n",
    "        # training graph\n",
    "        self._learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        self.loss = tf.reduce_mean(tf.square(self._Q - self._target))\n",
    "        # fixate on using this optimizer, otherwize, otherwise endup using unecessary graph nose\n",
    "        self.optimizer = tf.train.AdamOptimizer(self._learning_rate, name=\"Optimizer\")\n",
    "        self.train = self.optimizer.minimize(self.loss)   \n",
    "        \n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=1.0)\n",
    "        return tf.Variable(initial, name=\"weight\")\n",
    "        \n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "        return tf.Variable(initial, name=\"bias\")\n",
    "        \n",
    "    def batch_normalization(self, input, shape, gamma=None, beta=None):\n",
    "        # input should be hidden_dim\n",
    "        eps = 1e-5\n",
    "        if gamma is None:\n",
    "            gamma = tf.Variable(tf.constant(1.0, shape=shape))\n",
    "        if beta is None:\n",
    "            beta = tf.Variable(tf.constant(0.0, shape=shape))\n",
    "        mean, variance = tf.nn.moments(input, [0])\n",
    "        return gamma * (input - mean) / tf.sqrt(variance + eps) + beta\n",
    "    \n",
    "    def eps_greedy(self, eps, cash, stock, price, sess):\n",
    "        \"\"\"Return action chosen by greedy algorithm\"\"\"\n",
    "        u = np.random.uniform()\n",
    "        actions = [-1, 0, 1]\n",
    "        if u < 1 - eps:\n",
    "            q_list = []\n",
    "            for a in actions:\n",
    "                q = self._Q.eval(session=sess, \n",
    "                                 feed_dict={self._action: a, \n",
    "                                            self._cash: cash,\n",
    "                                            self._stock: stock,\n",
    "                                            self._price: price})\n",
    "                q_list.append(q)\n",
    "            action = actions[np.argmax(q_list)]\n",
    "        else:\n",
    "            action = actions[np.random.randint(0, 3)]\n",
    "        \n",
    "        return action\n",
    "                \n",
    "    \n",
    "    def training(self, whole_stock, trade_stock, n_memory=20, eps=0.1, init_cash=10000, init_stock=0, gam=0.95, learning_rate=1e-4, n_epochs=100):\n",
    "        \"\"\"training DQN which consider three actions; sell, buy, hold\n",
    "              money and n_stock are considered as state variable\n",
    "        \n",
    "        Args:\n",
    "            data (list): stock price for one company\n",
    "            n_memory (int): the number of data that is used for Experience Replay\n",
    "            eps (float): the epsilon of greedy epsilon used for behavior policy\n",
    "            init_cash (float): initial available cash\n",
    "            init_stock (int): the number of stock data \n",
    "        \"\"\"\n",
    "        init_op = tf.initialize_all_variables()\n",
    "        saver = tf.train.Saver()\n",
    "        T = len(whole_stock)\n",
    "        print_freq = int(n_epochs / 10)\n",
    "        \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_op)\n",
    "            value_list  = []\n",
    "            for epoch in xrange(n_epochs):\n",
    "                lr = learning_rate\n",
    "                cash = init_cash\n",
    "                stock = init_stock\n",
    "                price = whole_stock[0]\n",
    "                # memory pool used for Experience Replay\n",
    "                # length should be less than n_memory\n",
    "                memory = []\n",
    "                for t in xrange(T - 1):\n",
    "                    # select action with e-greedy\n",
    "                    # but:+1, hold: 0, sell -1\n",
    "                    action = self.eps_greedy(eps, cash, stock, price, sess)\n",
    "                    new_cash = cash - trade_stock[t] * action\n",
    "                    new_stock = stock + action\n",
    "                    new_price = whole_stock[t + 1]\n",
    "                    # add memory pools whose capacity is up to n_memory\n",
    "                    reward = new_stock * (trade_stock[t + 1] - trade_stock[t])\n",
    "                    transition = [cash, stock, price, action, reward, new_cash, new_stock, new_price]\n",
    "                    if len(memory) == n_memory:\n",
    "                        del memory[0]\n",
    "                    memory.append(transition)\n",
    "                    cash = new_cash\n",
    "                    stock = new_stock\n",
    "                    price = new_price\n",
    "                    \n",
    "                    # select transition from pool\n",
    "                    idx = np.random.randint(0, len(memory))\n",
    "                    trans = memory[idx]\n",
    "                    c = trans[0]\n",
    "                    s = trans[1]\n",
    "                    p = trans[2]\n",
    "                    a = trans[3]\n",
    "                    r = trans[4]\n",
    "                    new_c = trans[5]\n",
    "                    new_s = trans[6]\n",
    "                    new_p = trans[7]\n",
    "                    new_a = self.eps_greedy(eps, new_c, new_s, new_p, sess)\n",
    "                    q = self._Q.eval(session=sess, \n",
    "                                     feed_dict={self._action: new_a, \n",
    "                                                self._cash: new_c,\n",
    "                                                self._stock: new_s,\n",
    "                                                self._price: new_p})\n",
    "                    target = q + r\n",
    "                    sess.run(self.train, \n",
    "                             feed_dict={self._action: a, \n",
    "                                        self._cash: c,\n",
    "                                        self._stock: s,\n",
    "                                        self._price: p,\n",
    "                                        self._target: target,\n",
    "                                        self._learning_rate:lr})  \n",
    "                    \n",
    "                value = cash + trade_stock[-1] * stock\n",
    "                value_list.append(value)\n",
    "                if epoch % print_freq == 0:\n",
    "                    print (\"epoch: %d, final value:%f, stock:%d, cash:%f\" % (epoch, value, stock, cash))\n",
    "                    print (\"elapsed time:\", time.time() - st)\n",
    "           \n",
    "            # save_path = saver.save(sess, \"/jupyter/tomoaki/DQN/trained_params.ckpt\")\n",
    "            save_path = saver.save(sess, \"/home/tomoaki/alpaca/notebooks//DQN/trained_params.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "           \n",
    "        return value_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
